{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "nTNg0aoYxumN",
    "outputId": "4066efb2-2646-4e3d-a3bc-2c9802b341d9"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tWBAvaw5zIe_"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# BASE_PATH = \"/content/drive/My Drive/collab/\"\n",
    "BASE_PATH = \"/Users/samir/Dev/projects/MIMIC/\"\n",
    "input_path = BASE_PATH+\"MIMIC/DATA/input/\"\n",
    "output_path = BASE_PATH+\"MIMIC/DATA/results/\"\n",
    "tmp_path = BASE_PATH+\"MIMIC/DATA/processed/\"\n",
    "sys.path.append(BASE_PATH+\"TADAT/\") \n",
    "N_SEEDS=4\n",
    "PLOT_VARS=[\"auroc\",\"auprc\",\"sensitivity\",\"specificity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "vUQ7MBldvx5d",
    "outputId": "80c0e6f2-3d61-4b98-cbdc-687a441ee764"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import fnmatch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from pdb import set_trace\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score, auc, precision_recall_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "#local\n",
    "from tadat.pipeline import plots\n",
    "from tadat.core import data, vectorizer, features, helpers, embeddings, berter, transformer_lms\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-uckRCEvx61",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_cache(path):\n",
    "    pass\n",
    "    X = None\n",
    "    try:\n",
    "        with open(path, \"rb\") as fi:            \n",
    "            X = pickle.load(fi)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    return X\n",
    "\n",
    "def write_cache(path, o):\n",
    "    with open(path, \"wb\") as fo:\n",
    "        pickle.dump(o, fo)\n",
    "\n",
    "def clear_cache(cache_path, model=\"*\", dataset=\"*\", group=\"*\", ctype=\"*\"):\n",
    "    assert ctype in [\"*\",\"res*\",\"feats\"]\n",
    "    file_paths = os.listdir(cache_path)\n",
    "    pattern = \"{}_{}_{}_*_{}.pkl\".format(dataset, model, group, ctype).lower()\n",
    "    for fname in file_paths:\n",
    "        if fnmatch.fnmatch(fname, pattern):\n",
    "            os.remove(cache_path+\"/\"+fname)\n",
    "            print(\"cleared file: {}\".format(fname))\n",
    "        \n",
    "def plot_cached_results(cache_path, dataset, model):\n",
    "    file_paths = os.listdir(cache_path)\n",
    "    pattern = \"{}_{}_*_all_res.pkl\".format(dataset, model).lower()\n",
    "    for fname in file_paths:\n",
    "        if fnmatch.fnmatch(fname, pattern):\n",
    "            R = list(read_cache(cache_path+fname))\n",
    "            if \"gender\" in fname:\n",
    "                gender_plots(*R)\n",
    "            elif \"ethnicity_binary\" in fname:\n",
    "                ethnicity_binary_plots(*R)                \n",
    "            elif \"ethnicity\" in fname:\n",
    "                ethnicity_plots(*R)\n",
    "\n",
    "def get_deltas(results_G, results_O):\n",
    "    #resuts\n",
    "    df_G = pd.DataFrame(results_G)\n",
    "    df_O = pd.DataFrame(results_O)\n",
    "    #compute deltas\n",
    "    df_delta = df_G.sub(df_O.iloc[:,2:])\n",
    "    df_delta[\"model\"] = df_G[\"model\"]\n",
    "    df_delta[\"seed\"] = df_G[\"seed\"]   \n",
    "    return df_delta\n",
    "\n",
    "def plot_densities(df, ax, title):\n",
    "    ax.set_title(title)\n",
    "    for y in PLOT_VARS:        \n",
    "        try:\n",
    "            df.plot.kde(ax=ax, x=\"seed\", y=y)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "def plot_performance(df, title):\n",
    "    #plots\n",
    "    fig, ax = plt.subplots(1,2, figsize=(18,5))\n",
    "    plots.plot_df(df=df,ax=ax[0],x=\"seed\",ys=[\"auroc\",\"auprc\",\"sensitivity\",\"specificity\"], annotation_size=10)\n",
    "    \n",
    "    fig.suptitle(title ,y=1.02)\n",
    "    plot_densities(df, ax[1], \"\") \n",
    "    ax[0].legend(loc='best')\n",
    "    ax[1].legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "\n",
    "def read_dataset(path, dataset_name):\n",
    "    df_notes = pd.read_csv(\"{}/notes.csv\".format(path), sep=\"\\t\", header=0)\n",
    "    df_train = pd.read_csv(\"{}/{}_train.csv\".format(path, dataset_name), sep=\"\\t\", header=0)\n",
    "    df_test  = pd.read_csv(\"{}/{}_test.csv\".format(path, dataset_name), sep=\"\\t\", header=0)\n",
    "    df_val   = pd.read_csv(\"{}/{}_val.csv\".format(path, dataset_name), sep=\"\\t\", header=0)\n",
    "    \n",
    "    df_train = df_train.join(df_notes, on=\"SUBJECT_ID\", how=\"inner\", lsuffix=\"N_\")\n",
    "    df_test = df_test.join(df_notes, on=\"SUBJECT_ID\", how=\"inner\", lsuffix=\"N_\")\n",
    "    df_val = df_val.join(df_notes, on=\"SUBJECT_ID\", how=\"inner\", lsuffix=\"N_\")\n",
    "    \n",
    "    return df_train, df_test, df_val    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(data, vocab_size, feature_type, word_vectors=None):\n",
    "    if feature_type == \"BOW-BIN\":\n",
    "        X = features.BOW(data, vocab_size,sparse=True)\n",
    "    elif feature_type == \"BOW-FREQ\":\n",
    "        X = features.BOW_freq(data, vocab_size,sparse=True)\n",
    "    elif feature_type == \"BOE-BIN\":\n",
    "        X = features.BOE(data, word_vectors,\"bin\")\n",
    "    elif feature_type == \"BOE-SUM\": \n",
    "        X = features.BOE(data, word_vectors,\"sum\")\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return X\n",
    "    \n",
    "def get_BERT_embedding(X, feature_type):\n",
    "    X_cls, X_pool =  transformer_lms.transformer_encode_batches(X, batchsize=200, device=\"cuda\")\n",
    "    if feature_type == \"BERT-POOL\":\n",
    "        return X_pool\n",
    "    elif feature_type == \"BERT-CLS\":\n",
    "        return X_cls\n",
    "\n",
    "\n",
    "def featurize(df_train, df_test, feature_type, group_label, subgroup):\n",
    "    df_test_G = df_test[df_test[group_label] == subgroup]\n",
    "    df_test_O = df_test[df_test[group_label] != subgroup]\n",
    "    \n",
    "    print(\"{}: {} | others: {}\".format(subgroup,len(df_test_G),len(df_test_O)))\n",
    "    #transform the data into the right format\n",
    "    train = data.read_dataframe(df_train, \"TEXT\", \"Y\")\n",
    "    test_G = data.read_dataframe(df_test_G, \"TEXT\", \"Y\")\n",
    "    test_O = data.read_dataframe(df_test_O, \"TEXT\", \"Y\")\n",
    "    test = data.read_dataframe(df_test, \"TEXT\", \"Y\")\n",
    "\n",
    "    #get vectorized train/test data \n",
    "    train_X = data.getX(train)\n",
    "    test_X_G = data.getX(test_G)\n",
    "    test_X_O = data.getX(test_O)\n",
    "    test_X = data.getX(test)\n",
    "    \n",
    "    train_X, word_vocab = vectorizer.docs2idx(train_X)\n",
    "    test_X_G,_ = vectorizer.docs2idx(test_X_G, word_vocab)\n",
    "    test_X_O,_ = vectorizer.docs2idx(test_X_O, word_vocab)\n",
    "    test_X,_ = vectorizer.docs2idx(test_X, word_vocab)\n",
    "    \n",
    "    #vectorize labels\n",
    "    train_Y = data.getY(train)\n",
    "    test_Y_G = data.getY(test_G) \n",
    "    test_Y_O = data.getY(test_O)   \n",
    "    test_Y = data.getY(test)   \n",
    "    \n",
    "    label_vocab = vectorizer.get_labels_vocab(train_Y+test_Y)\n",
    "    train_Y,_ = vectorizer.label2idx(train_Y, label_vocab)\n",
    "    test_Y,_ = vectorizer.label2idx(test_Y, label_vocab)\n",
    "    test_Y_G,_ = vectorizer.label2idx(test_Y_G, label_vocab)\n",
    "    test_Y_O,_ = vectorizer.label2idx(test_Y_O, label_vocab)\n",
    "    \n",
    "    if \"BOW\" in feature_type:\n",
    "        #extract features\n",
    "        train_feats = get_features(train_X, len(word_vocab), feature_type)\n",
    "        test_feats_G = get_features(test_X_G, len(word_vocab), feature_type)\n",
    "        test_feats_O = get_features(test_X_O, len(word_vocab), feature_type)        \n",
    "        test_feats = get_features(test_X, len(word_vocab), feature_type)        \n",
    "    elif \"BERT\" in feature_type:\n",
    "        train_feats = get_BERT_embedding(train, feature_type)\n",
    "        test_feats_G = get_BERT_embedding(test_G, feature_type)\n",
    "        test_feats_O = get_BERT_embedding(test_O, feature_type)\n",
    "        test_feats = get_BERT_embedding(test, feature_type)\n",
    "    else:\n",
    "        raise NotImplementedError    \n",
    "\n",
    "    return train_feats, train_Y, test_feats, test_Y, test_feats_G, test_Y_G, test_feats_O, test_Y_O, label_vocab\n",
    "\n",
    "def run(data_path, dataset, feature_type, group_label, subgroup, split=0.8, cache_path=None):\n",
    "    if \"FINE-BERT\" in feature_type:\n",
    "        return run_finebert(data_path, dataset, feature_type, group_label, subgroup, split, cache_path)    \n",
    "    feats_fname = \"{}{}_{}_{}_{}_feats.pkl\".format(cache_path, dataset, feature_type, group_label, subgroup).lower()    \n",
    "    X=None\n",
    "    #check if the features were already computed and cached    \n",
    "    if cache_path: X = read_cache(feats_fname)      \n",
    "    #if features were not cached, read the data and extract features\n",
    "    if not X:\n",
    "        df_train, df_test, df_val = read_dataset(data_path, dataset)\n",
    "        X = featurize(df_train, df_test, feature_type, group_label, subgroup)\n",
    "        #cache current features\n",
    "        if cache_path: write_cache(feats_fname, X)            \n",
    "    else:\n",
    "        print(\"loaded cached features\")  \n",
    "    train_feats, train_Y, test_feats, test_Y, test_feats_G, test_Y_G, test_feats_O, test_Y_O, label_vocab = X        \n",
    "    print(\"train set size: \", train_feats.shape[0])\n",
    "    #train/test classifier for each random seed\n",
    "    random_seeds = list(range(N_SEEDS))\n",
    "    results = []\n",
    "    results_g = []\n",
    "    results_o = []\n",
    "    \n",
    "    for seed in random_seeds:        \n",
    "        res_fname = \"{}{}_{}_{}_{}_res{}.pkl\".format(cache_path, dataset, feature_type, group_label, subgroup, seed ).lower()\n",
    "        R=None\n",
    "        #look for cached results\n",
    "        if cache_path: R = read_cache(res_fname)                      \n",
    "        if not R:\n",
    "            model = SGDClassifier(loss=\"log\", random_state=seed)\n",
    "            model.fit(train_feats, train_Y)\n",
    "            res = evaluate_classifier(model, test_feats, test_Y, label_vocab, feature_type, seed)\n",
    "            res_g = evaluate_classifier(model, test_feats_G, test_Y_G, label_vocab, feature_type, seed)\n",
    "            res_o = evaluate_classifier(model, test_feats_O, test_Y_O, label_vocab, feature_type, seed)\n",
    "            #cache results\n",
    "            if cache_path: write_cache(res_fname, [res, res_g, res_o])                \n",
    "        else:\n",
    "            print(\"loaded cached results | seed: {}\".format(seed))\n",
    "            res, res_g, res_o = R\n",
    "        results.append(res)\n",
    "        results_g.append(res_g)\n",
    "        results_o.append(res_o)\n",
    "    return results, results_g, results_o\n",
    "\n",
    "def bert_featurize(df_train, df_test, df_val, group_label, subgroup, split):\n",
    "    #split data into \"group\" and \"others\"\n",
    "    df_test_G = df_test[df_test[group_label] == subgroup]\n",
    "    df_test_O = df_test[df_test[group_label] != subgroup]    \n",
    "    print(\"{}: {} | OTHERS: {}\".format(subgroup,len(df_test_G),len(df_test_O)))\n",
    "    #transform the data into the right format\n",
    "    train = data.read_dataframe(df_train, \"TEXT\", \"Y\")\n",
    "    test_G = data.read_dataframe(df_test_G, \"TEXT\", \"Y\")\n",
    "    test_O = data.read_dataframe(df_test_O, \"TEXT\", \"Y\")\n",
    "    test = data.read_dataframe(df_test,  \"TEXT\", \"Y\")\n",
    "    val = data.read_dataframe(df_val,  \"TEXT\", \"Y\")    \n",
    "    #get instances...\n",
    "    train_X = data.getX(train)\n",
    "    test_X_G = data.getX(test_G)\n",
    "    test_X_O = data.getX(test_O)\n",
    "    test_X = data.getX(test)\n",
    "    val_X = data.getX(val)  \n",
    "    #...and labels\n",
    "    train_Y = data.getY(train)\n",
    "    test_Y_G = data.getY(test_G) \n",
    "    test_Y_O = data.getY(test_O)   \n",
    "    test_Y = data.getY(test)  \n",
    "    val_Y = data.getY(val)      \n",
    "    \n",
    "    # #find max sentence length\n",
    "    # all_docs = np.concatenate([train_X,test_X,val_X])\n",
    "    # max_len = berter.max_doc_len(all_docs)\n",
    "    # print('Max length: ', max_len)   \n",
    "    max_len = 512\n",
    "    #vectorize labels\n",
    "    label_vocab = vectorizer.get_labels_vocab(train_Y+test_Y+val_Y)\n",
    "    train_Y,_ = vectorizer.label2idx(train_Y, label_vocab)\n",
    "    val_Y,_ = vectorizer.label2idx(val_Y, label_vocab)\n",
    "    test_Y,_ = vectorizer.label2idx(test_Y, label_vocab)\n",
    "    test_Y_G,_ = vectorizer.label2idx(test_Y_G, label_vocab)\n",
    "    test_Y_O,_ = vectorizer.label2idx(test_Y_O, label_vocab)        \n",
    "    #vectorize data\n",
    "    train_inputs, train_masks, train_labels = berter.vectorize(train_X, train_Y, max_len)\n",
    "    val_inputs, val_masks, val_labels = berter.vectorize(val_X, val_Y, max_len)\n",
    "    test_inputs, test_masks, test_labels = berter.vectorize(test_X, test_Y, max_len)\n",
    "    test_inputs_G, test_masks_G, test_labels_G = berter.vectorize(test_X_G, test_Y_G, max_len)\n",
    "    test_inputs_O, test_masks_O, test_labels_O = berter.vectorize(test_X_O, test_Y_O, max_len)\n",
    "\n",
    "    BATCH_SIZE = 32\n",
    "    # Create the DataLoader for training and validation sets\n",
    "    train_loader = berter.get_random_sample_loader(train_inputs, train_masks, train_labels, BATCH_SIZE)\n",
    "    val_loader = berter.get_sequential_sample_loader(val_inputs, val_masks, val_labels, BATCH_SIZE)\n",
    "    test_loader = berter.get_sequential_sample_loader(test_inputs, test_masks, test_labels, BATCH_SIZE)\n",
    "    test_loader_G = berter.get_sequential_sample_loader(test_inputs_G, test_masks_G, test_labels_G, BATCH_SIZE)\n",
    "    test_loader_O = berter.get_sequential_sample_loader(test_inputs_O, test_masks_O, test_labels_O, BATCH_SIZE)  \n",
    "\n",
    "    return train_loader, train_Y, val_loader, val_Y, test_loader, test_Y, test_loader_G, test_Y_G, test_loader_O, test_Y_O, label_vocab\n",
    "\n",
    "def run_finebert(data_path, dataset, feature_type, group_label, subgroup, split=0.8, cache_path=None):\n",
    "    print(\"FINE BERT\")    \n",
    "    feats_fname = \"{}{}_{}_{}_{}_feats.pkl\".format(cache_path, dataset, feature_type, group_label, subgroup).lower()\n",
    "    X=None\n",
    "    #check if the features were already computed and cached\n",
    "    if cache_path: X = read_cache(feats_fname)      \n",
    "    #if features were not cached, read the data and extract features\n",
    "    if not X:\n",
    "        df_train, df_test, df_val = read_dataset(data_path, dataset)\n",
    "        X = bert_featurize(df_train, df_test, df_val, feature_type, group_label, subgroup)\n",
    "        #cache current features\n",
    "        if cache_path: write_cache(feats_fname, X)            \n",
    "    else:\n",
    "        print(\"loaded cached features\")  \n",
    "    train_loader, train_Y, val_loader, val_Y, test_loader, test_Y, test_loader_G, test_Y_G, test_loader_O, test_Y_O, label_vocab = X        \n",
    "    print(\"train set size: \",  len(train_loader))\n",
    "    #train/test classifier for each random seed\n",
    "    random_seeds = list(range(N_SEEDS))\n",
    "    results = []\n",
    "    results_g = []\n",
    "    results_o = []\n",
    "\n",
    "    #pool features (vs CLS)    \n",
    "    pool = \"POOL\" in feature_type\n",
    "    \n",
    "    for seed in random_seeds:        \n",
    "        res_fname = \"{}{}_{}_{}_{}_res{}.pkl\".format(cache_path, dataset, feature_type, group_label, subgroup, seed ).lower()\n",
    "        R = None\n",
    "        #look for cached results        \n",
    "        if cache_path: R = read_cache(res_fname)    \n",
    "        if not R:\n",
    "            model = berter.BertClassifier(freeze_bert=True, pool=pool)\n",
    "            model.fit(train_loader, val_loader, epochs=1, validation=True, seed=seed)        \n",
    "            res = evaluate_classifier(model, test_loader, test_Y, label_vocab, feature_type, seed)            \n",
    "            res_g = evaluate_classifier(model, test_loader_G, test_Y_G, label_vocab, feature_type, seed)\n",
    "            res_o = evaluate_classifier(model, test_loader_O, test_Y_O, label_vocab, feature_type, seed)                        \n",
    "            results.append(res)\n",
    "            results_g.append(res_g)            \n",
    "            results_o.append(res_o)\n",
    "            #cache results            \n",
    "            if cache_path: write_cache(res_fname, [res, res_g, res_o])                \n",
    "        else:\n",
    "            print(\"loaded cached results | seed: {}\".format(seed))\n",
    "            res, res_g, res_o = R\n",
    "        results.append(res)\n",
    "        results_g.append(res_g)\n",
    "        results_o.append(res_o)\n",
    "    return results, results_g, results_o\n",
    "\n",
    "def evaluate_classifier(model, X_test, Y_test,\n",
    "                   labels, model_name, random_seed, res_path=None):\n",
    "    Y_hat = model.predict(X_test)\n",
    "    Y_hat_prob = model.predict_proba(X_test)\n",
    "    #get probabilities for the positive class\n",
    "    Y_hat_prob = Y_hat_prob[:,labels[1]]\n",
    "    \n",
    "    microF1 = f1_score(Y_test, Y_hat, average=\"micro\") \n",
    "    macroF1 = f1_score(Y_test, Y_hat, average=\"macro\") \n",
    "    aurocc = roc_auc_score(Y_test, Y_hat_prob)\n",
    "    prec, rec, thresholds = precision_recall_curve(Y_test, Y_hat)\n",
    "    auprc = auc(rec, prec)\n",
    "    tn, fp, fn, tp = confusion_matrix(Y_test, Y_hat).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    sensitivity = tp / (fn+tp)\n",
    "    \n",
    "    res = {\"model\":model_name, \n",
    "            \"seed\":random_seed,    \n",
    "            \"microF1\":round(microF1,3),\n",
    "            \"macroF1\":round(macroF1,3),\n",
    "            \"auroc\":round(aurocc,3),\n",
    "            \"auprc\":round(auprc,3),\n",
    "            \"specificity\":round(specificity,3),\n",
    "            \"sensitivity\":round(sensitivity,3)           \n",
    "            }\n",
    "\n",
    "    if res_path is not None:    \n",
    "        helpers.save_results(res, res_path, sep=\"\\t\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kTyzgoy4vx64"
   },
   "source": [
    "# Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vz6CiKv4xEp8"
   },
   "source": [
    "## Ethnicity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kNxNa35Cvx65"
   },
   "outputs": [],
   "source": [
    "def ethnicity_plot_deltas(df_delta_W,df_delta_N,df_delta_A,df_delta_H, title):\n",
    "    df_delta = pd.concat([df_delta_W,df_delta_N,df_delta_A,df_delta_H])    \n",
    "    #transform results into \"long format\"\n",
    "    df_delta_long = df_delta.melt(id_vars=[\"seed\",\"model\",\"group\"], value_vars=PLOT_VARS, \n",
    "                                        var_name=\"metric\", value_name=\"delta\")\n",
    "    g = sns.catplot(x=\"metric\", y=\"delta\", data=df_delta_long, \n",
    "                    col=\"group\",sharey=True,legend=False)\n",
    "    ax1, ax2, ax3, ax4 = g.axes[0]\n",
    "    ax1.axhline(0, ls='--',c=\"r\")\n",
    "    ax2.axhline(0, ls='--',c=\"r\")\n",
    "    ax3.axhline(0, ls='--',c=\"r\")\n",
    "    ax4.axhline(0, ls='--',c=\"r\")\n",
    "    lim = max(df_delta_long[\"delta\"].abs()) + 0.05\n",
    "    ax1.set_ylim([-lim,lim])\n",
    "    ax2.set_ylim([-lim,lim])\n",
    "    ax3.set_ylim([-lim,lim])\n",
    "    ax4.set_ylim([-lim,lim])\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()  \n",
    "\n",
    "def ethnicity_plot_densities(df_W, df_N, df_A, df_H, title):\n",
    "    #plots\n",
    "    fig, ax = plt.subplots(1,4, sharey=True, sharex=True, figsize=(18,5))\n",
    "    plot_densities(df_W, ax[0], \"White\")\n",
    "    plot_densities(df_N, ax[1], \"Black\")\n",
    "    plot_densities(df_A, ax[2], \"Asian\")\n",
    "    plot_densities(df_H, ax[3], \"Hispanic\")\n",
    "    fig.suptitle(title,  y=1.02)\n",
    "    plt.tight_layout()\n",
    "\n",
    "def ethnicity_plots(df_res, df_res_W, df_res_N, df_res_A, df_res_H, df_res_delta_W, \n",
    "                      df_res_delta_N,df_res_delta_A, df_res_delta_H, title):\n",
    "    plot_performance(df_res, title)\n",
    "    ethnicity_plot_densities(df_res_W,df_res_N,df_res_A,df_res_H,title)\n",
    "    ethnicity_plot_deltas(df_res_delta_W, df_res_delta_N,df_res_delta_A,df_res_delta_H, title)\n",
    "\n",
    "def ethnicity_outcomes(data_path, dataset, feature_type, cache_path=None):\n",
    "\n",
    "    results_W, results_G_W, results_O_W = run(data_path, dataset, feature_type, \"ETHNICITY_LABEL\", \n",
    "                                              \"WHITE\", split=0.8, cache_path=cache_path)\n",
    "    results_N, results_G_N, results_O_N = run(data_path, dataset, feature_type, \"ETHNICITY_LABEL\", \n",
    "                                              \"BLACK\", split=0.8, cache_path=cache_path)\n",
    "    results_A, results_G_A, results_O_A = run(data_path, dataset, feature_type, \"ETHNICITY_LABEL\", \n",
    "                                              \"ASIAN\", split=0.8, cache_path=cache_path)\n",
    "    results_H, results_G_H, results_O_H = run(data_path, dataset, feature_type, \"ETHNICITY_LABEL\",\n",
    "                                              \"HISPANIC\", split=0.8, cache_path=cache_path)\n",
    "\n",
    "    #results\n",
    "    df_delta_W = get_deltas(results_G_W,results_O_W)\n",
    "    df_delta_N = get_deltas(results_G_N,results_O_N)\n",
    "    df_delta_A = get_deltas(results_G_A,results_O_A)\n",
    "    df_delta_H = get_deltas(results_G_H,results_O_H)\n",
    "\n",
    "    df_res = pd.DataFrame(results_W)\n",
    "    df_res_W = pd.DataFrame(results_G_W)\n",
    "    df_res_N = pd.DataFrame(results_G_N)\n",
    "    df_res_A = pd.DataFrame(results_G_A)\n",
    "    df_res_H = pd.DataFrame(results_G_H)\n",
    "\n",
    "    df_delta_W[\"group\"] = [\"White v Others\"]*len(df_delta_W)\n",
    "    df_delta_N[\"group\"] = [\"Black v Others\"]*len(df_delta_N)\n",
    "    df_delta_A[\"group\"] = [\"Asian v Others\"]*len(df_delta_A)\n",
    "    df_delta_H[\"group\"] = [\"Hispanic v Others\"]*len(df_delta_H)\n",
    "    \n",
    "    return df_res, df_res_W, df_res_N, df_res_A, df_res_H, df_delta_W, df_delta_N, df_delta_A, df_delta_H\n",
    "\n",
    "def ethnicity_analysis(data_path, dataset, feature_type, output_path, cache_path=None, plots=True):\n",
    "    R  = ethnicity_outcomes(data_path, dataset, feature_type, cache_path)\n",
    "    df_res, df_res_W, df_res_N, df_res_A, df_res_H, df_res_delta_W, df_res_delta_N,df_res_delta_A, df_res_delta_H = R    \n",
    "    #save results\n",
    "    title=\"{} x ethnicity x {}\".format(dataset, feature_type).lower()        \n",
    "    fname = \"{}{}_{}_ethnicity_all_res.pkl\".format(output_path, dataset, feature_type).lower()\n",
    "    with open(fname, \"wb\") as fo:\n",
    "        pickle.dump([df_res, df_res_W, df_res_N, df_res_A, df_res_H, df_res_delta_W, \n",
    "                     df_res_delta_N,df_res_delta_A, df_res_delta_H, title], fo)\n",
    "    if plots:\n",
    "        ethnicity_plots(df_res, df_res_W, df_res_N, df_res_A, df_res_H, \n",
    "                          df_res_delta_W, df_res_delta_N,df_res_delta_A, df_res_delta_H, title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cFe5X5pWxEp3"
   },
   "source": [
    "## Ethnicity Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rIQe7-IPxEp4"
   },
   "outputs": [],
   "source": [
    "def ethnicity_binary_plot_deltas(df_delta_W,df_delta_N, title):\n",
    "    df_delta = pd.concat([df_delta_W,df_delta_N])    \n",
    "    #transform results into \"long format\"\n",
    "    df_delta_long = df_delta.melt(id_vars=[\"seed\",\"model\",\"group\"], value_vars=PLOT_VARS, \n",
    "                                        var_name=\"metric\", value_name=\"delta\")\n",
    "\n",
    "    g = sns.catplot(x=\"metric\", y=\"delta\", data=df_delta_long, \n",
    "                    col=\"group\",sharey=True,legend=False)\n",
    "    ax1, ax2 = g.axes[0]\n",
    "    ax1.axhline(0, ls='--',c=\"r\")\n",
    "    ax2.axhline(0, ls='--',c=\"r\")\n",
    "    lim = max(df_delta_long[\"delta\"].abs()) + 0.05\n",
    "    ax1.set_ylim([-lim,lim])\n",
    "    ax2.set_ylim([-lim,lim])\n",
    "    plt.suptitle(title,y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()  \n",
    "    \n",
    "def ethnicity_binary_plot_densities(df_W, df_N, title):\n",
    "    #plots\n",
    "    fig, ax = plt.subplots(1,2, sharey=True, sharex=True, figsize=(18,5))\n",
    "    plot_densities(df_W, ax[0], \"White\")\n",
    "    plot_densities(df_N, ax[1], \"Non-White\")\n",
    "    fig.suptitle(title ,y=1.02)\n",
    "    plt.tight_layout()\n",
    "\n",
    "def ethnicity_binary_plots(df_res, df_res_W, df_res_N, df_res_delta_W, df_res_delta_N, title):\n",
    "    plot_performance(df_res, title)\n",
    "    ethnicity_binary_plot_densities(df_res_W,df_res_N,title)\n",
    "    ethnicity_binary_plot_deltas(df_res_delta_W, df_res_delta_N, title)\n",
    "\n",
    "def ethnicity_binary_outcomes(data_path, dataset, feature_type, cache_path=None):\n",
    "    results_W, results_G_W, results_O_W = run(data_path, dataset, feature_type, \"ETHNICITY_BINARY\", \n",
    "                                              \"WHITE\", split=0.8, cache_path=cache_path)\n",
    "    results_N, results_G_N, results_O_N = run(data_path, dataset, feature_type, \"ETHNICITY_BINARY\", \n",
    "                                              \"NON-WHITE\", split=0.8, cache_path=cache_path)\n",
    "    #results\n",
    "    df_delta_W = get_deltas(results_G_W,results_O_W)\n",
    "    df_delta_N = get_deltas(results_G_N,results_O_N)    \n",
    "    df_delta_W[\"group\"] = [\"White v Others\"]*len(df_delta_W)\n",
    "    df_delta_N[\"group\"] = [\"Non-White v Others\"]*len(df_delta_N)\n",
    "    df_res = pd.DataFrame(results_W)    \n",
    "    df_res_W = pd.DataFrame(results_G_W)\n",
    "    df_res_N = pd.DataFrame(results_G_N)\n",
    "    \n",
    "    return df_res, df_res_W, df_res_N, df_delta_W, df_delta_N\n",
    "   \n",
    "def ethnicity_binary_analysis(data_path, dataset, feature_type, output_path, cache_path=None, plots=True):\n",
    "    df_res, df_res_W, df_res_N, df_res_delta_W, df_res_delta_N = ethnicity_binary_outcomes(data_path, dataset, \n",
    "                                                                                           feature_type, cache_path)    \n",
    "    #save results\n",
    "    title=\"{} x ethnicity-binary x {}\".format(dataset, feature_type).lower()\n",
    "    fname = \"{}{}_{}_ethnicity_binary_all_res.pkl\".format(output_path, dataset, feature_type).lower()\n",
    "    with open(fname, \"wb\") as fo:\n",
    "        pickle.dump([df_res, df_res_W, df_res_N, df_res_delta_W, df_res_delta_N, title], fo)\n",
    "\n",
    "    if plots:\n",
    "        ethnicity_binary_plots(df_res, df_res_W, df_res_N, df_res_delta_W, df_res_delta_N,title)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lLmcgnVHxEpo"
   },
   "source": [
    "## Gender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0SvZXhVwxEpq"
   },
   "outputs": [],
   "source": [
    "def gender_plot_deltas(df_delta, title):\n",
    "    #transform results into \"long format\"\n",
    "    df_delta_long = df_delta.melt(id_vars=[\"seed\",\"model\"], value_vars=PLOT_VARS, \n",
    "                                        var_name=\"metric\", value_name=\"delta\")\n",
    "    \n",
    "    lim = max(df_delta_long[\"delta\"].abs()) + 0.05\n",
    "    g = sns.catplot(x=\"metric\", y=\"delta\",  data=df_delta_long, sharey=True,legend=False)\n",
    "    ax1 = g.axes[0][0]\n",
    "    ax1.axhline(0, ls='--',c=\"r\")\n",
    "    ax1.set_ylim([-lim,lim])\n",
    "    plt.suptitle(title,y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()  \n",
    "\n",
    "def gender_plot_densities(df_M, df_F, title):\n",
    "    #plots\n",
    "    fig, ax = plt.subplots(1,2, sharey=True, sharex=True, figsize=(18,5))\n",
    "    plot_densities(df_M, ax[0], \"Male\") \n",
    "    plot_densities(df_F, ax[1], \"Female\") \n",
    "    fig.suptitle(title, y=1.02)\n",
    "    plt.tight_layout()\n",
    "\n",
    "def gender_outcomes(data_path, dataset, feature_type, cache_path):\n",
    "    results, results_M, results_F = run(data_path, dataset, feature_type, \n",
    "                                        \"GENDER\", \"M\", split=0.8, cache_path=cache_path)\n",
    "    #results\n",
    "    df_delta = get_deltas(results_M,results_F)    \n",
    "    df_res = pd.DataFrame(results)    \n",
    "    df_res_M = pd.DataFrame(results_M)\n",
    "    df_res_F = pd.DataFrame(results_F)\n",
    "    \n",
    "    return df_res, df_res_M, df_res_F, df_delta\n",
    "\n",
    "def gender_plots(df_res, df_res_M, df_res_F, df_res_delta, title):\n",
    "    plot_performance(df_res, title)\n",
    "    gender_plot_densities(df_res_M, df_res_F, title)\n",
    "    gender_plot_deltas(df_res_delta, title)    \n",
    "    \n",
    "def gender_analysis(data_path, dataset, feature_type, output_path, cache_path=None, plots=True):\n",
    "    df_res, df_res_M, df_res_F, df_res_delta = gender_outcomes(data_path, dataset, feature_type, cache_path)\n",
    "    #save results\n",
    "    title=\"{} x gender x {}\".format(dataset, feature_type).lower()\n",
    "    fname = \"{}{}_{}_gender_all_res.pkl\".format(output_path, dataset, feature_type).lower()\n",
    "    with open(fname, \"wb\") as fo:\n",
    "        pickle.dump([df_res, df_res_M, df_res_F, df_res_delta, title], fo)        \n",
    "\n",
    "    if plots:\n",
    "        gender_plots(df_res, df_res_M, df_res_F, df_res_delta, title)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Z8CaIW1xEqA"
   },
   "source": [
    "# Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BzVIL2tV5a3J"
   },
   "outputs": [],
   "source": [
    "model=\"BOW-BIN\"\n",
    "dataset=\"CAAOHD\"\n",
    "dataset=\"mini_\"+dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nkEC7jaExEqC",
    "outputId": "15c448f3-be23-4940-8787-98a08e23b2db"
   },
   "outputs": [],
   "source": [
    "gender_analysis(input_path, dataset, model, output_path, tmp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_MUo-Ek7xEqJ",
    "outputId": "47008362-bf8f-462d-a671-358ae8fd4ea8"
   },
   "outputs": [],
   "source": [
    "ethnicity_binary_analysis(input_path, dataset, model, output_path, tmp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "62PxP1xKxEqN"
   },
   "outputs": [],
   "source": [
    "ethnicity_analysis(input_path, dataset, model, output_path, tmp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_cached_results(output_path, dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cache(tmp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MIMIC Outcomes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
