{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nTNg0aoYxumN"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4h40mg5Ocpz2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWBAvaw5zIe_"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# BASE_PATH = \"/content/drive/My Drive/collab/MIMIC/\"\n",
    "BASE_PATH = \"/Users/samir/Dev/projects/MIMIC/MIMIC/\"\n",
    "INPUT_PATH = BASE_PATH+\"/DATA/input/\"\n",
    "FEATURES_PATH = BASE_PATH+\"/DATA/features/\"\n",
    "OUTPUT_PATH = BASE_PATH+\"/DATA/results/\"\n",
    "TMP_PATH = BASE_PATH+\"/DATA/processed/\"\n",
    "\n",
    "TUNE_OUTPUT_PATH = BASE_PATH+\"/DATA/tune_results/\"\n",
    "TUNE_TMP_PATH = BASE_PATH+\"/DATA/tune_processed/\"\n",
    "\n",
    "\n",
    "sys.path.append(\"/content/drive/My Drive/collab/TADAT/\") \n",
    "\n",
    "#configs\n",
    "N_SEEDS=8\n",
    "N_VAL_SEEDS = 4\n",
    "N_VAL_RUNS = 4\n",
    "N_TASKS = 3\n",
    "# N_TASKS = 50\n",
    "# PLOT_VARS=[\"auroc\",\"auprc\",\"sensitivity\",\"specificity\"]\n",
    "PLOT_VARS=[\"auroc\",\"sensitivity\"]\n",
    "MODEL=\"BERT-POOL\"\n",
    "\n",
    "# GROUPS = { \"GENDER\": [\"M\",\"F\"],\n",
    "#          \"ETHNICITY_BINARY\": [\"WHITE\",\"NON-WHITE\"],\n",
    "#          \"ETHNICITY\": [\"WHITE\",\"BLACK\",\"ASIAN\",\"HISPANIC\"]\n",
    "# }\n",
    "GROUPS = { \"GENDER\": [\"M\",\"F\"],   \n",
    "         \"ETHNICITY\": [\"WHITE\",\"BLACK\",\"ASIAN\",\"HISPANIC\"]\n",
    "}\n",
    "\n",
    "MAJORITY_GROUP = { \"GENDER\": \"M\",\n",
    "                   \"ETHNICITY_BINARY\": \"WHITE\",\n",
    "                    \"ETHNICITY\": \"WHITE\" }\n",
    "CLASSIFIER = 'sklearn'\n",
    "CLASSIFIER = 'torch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUQ7MBldvx5d"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import dill\n",
    "import fnmatch\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import os\n",
    "from pdb import set_trace\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pprint\n",
    "import random\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score, auc, precision_recall_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import torch\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "#local\n",
    "from tadat.pipeline import plots\n",
    "from tadat.core import data, vectorizer, features, helpers, embeddings, berter, transformer_lms, transformer_encoders\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3e7c8851e8ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#torch model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mMyLinearModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     def __init__(self, in_dim, out_dim, loss_fn, optimizer=None, \n\u001b[1;32m      4\u001b[0m                  \u001b[0mdefault_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#torch model\n",
    "class MyLinearModel(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, loss_fn, optimizer=None, \n",
    "                 default_lr=None, init_seed=None, n_epochs=4, \n",
    "                 batch_size=None, shuffle_seed=None, silent=False, \n",
    "                 shuffle=False, device=None):\n",
    "        super().__init__()\n",
    "        if not device: self.device = get_device(silent=True)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle_seed = shuffle_seed\n",
    "        self.shuffle = shuffle\n",
    "        self.silent = silent\n",
    "        self.loss_fn = loss_fn\n",
    "        self.n_epochs = n_epochs\n",
    "        self.model = torch.nn.Linear(in_dim, out_dim)\n",
    "        if init_seed: \n",
    "            torch.manual_seed(init_seed)        \n",
    "            #initialize random weights\n",
    "            torch.nn.init.uniform_(self.model.weight, a=-1, b=1)\n",
    "        if optimizer:\n",
    "            self.optimizer = optimizer(self.model.parameters())\n",
    "        else:\n",
    "            if default_lr:\n",
    "                self.optimizer = torch.optim.Adam(self.model.parameters(), \n",
    "                                                  lr=default_lr)\n",
    "            else:\n",
    "                self.optimizer = torch.optim.Adam(self.model.parameters())\n",
    "\n",
    "    def forward(self, in_dim, out_dim):\n",
    "        return self.model(in_dim, out_dim)\n",
    "\n",
    "    def fit(self, X_train, Y_train, X_val, Y_val):      \n",
    "        X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "        Y_train = torch.tensor(Y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "        X_val = torch.from_numpy(X_val.astype(np.float32))\n",
    "        Y_val = torch.tensor(Y_val, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "        train_len = X_train.shape[0]        \n",
    "        rng = RandomState(self.shuffle_seed)        \n",
    "        if not self.batch_size:        \n",
    "            self.batch_size = train_len\n",
    "            n_batches = 1\n",
    "        else:\n",
    "            n_batches = int(train_len/self.batch_size)+1            \n",
    "        #send validation data and model to device\n",
    "        X_val_ = X_val.to(self.device) \n",
    "        Y_val_ = Y_val.to(self.device)\n",
    "        X_train_ = X_train.to(self.device)\n",
    "        Y_train_ = Y_train.to(self.device)\n",
    "        self.model = self.model.to(self.device) \n",
    "        idx = torch.tensor(rng.permutation(train_len))\n",
    "        idx_ = idx.to(self.device) \n",
    "\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        val_loss_value=float('inf') \n",
    "        best_val_loss=float('inf')     \n",
    "        n_val_drops=0   \n",
    "        MAX_VAL_DROPS=10\n",
    "        loss_margin = 1e-3      \n",
    "        tmp_model_fname = str(uuid.uuid4())+\".pt\"\n",
    "        if not self.silent: print(\"[tmp: {}]\".format(tmp_model_fname))\n",
    "        for it in range(self.n_epochs):    \n",
    "            t0_epoch = time.time()\n",
    "            if self.shuffle:                                     \n",
    "                X_train_ = X_train[idx_].to(self.device)\n",
    "                Y_train_ = Y_train[idx_].to(self.device)                        \n",
    "                idx = torch.tensor(rng.permutation(train_len))\n",
    "                idx_ = idx.to(self.device) \n",
    "            for j in range(n_batches):                \n",
    "                x_train = X_train_[j*self.batch_size:(j+1)*self.batch_size, :]\n",
    "                y_train = Y_train_[j*self.batch_size:(j+1)*self.batch_size]                \n",
    "                y_hat_train = self.model(x_train)\n",
    "                train_loss = self.loss_fn(y_hat_train, y_train)                \n",
    "                train_loss_value = train_loss.item()\n",
    "                self.optimizer.zero_grad()\n",
    "                train_loss.backward()\n",
    "                self.optimizer.step()                \n",
    "                train_losses.append(train_loss_value)        \n",
    "                val_losses.append(val_loss_value)   \n",
    "            outputs_val = self.model(X_val_)\n",
    "            val_loss = self.loss_fn(outputs_val, Y_val_)      \n",
    "            val_loss_value =  val_loss.item()     \n",
    "            if val_loss_value < best_val_loss:    \n",
    "                n_val_drops=0            \n",
    "                best_val_loss = val_loss\n",
    "                #save best model\n",
    "                # print(\"[updating best model]\")\n",
    "                torch.save(self.model.state_dict(), tmp_model_fname)\n",
    "            elif val_loss_value > best_val_loss - loss_margin:                \n",
    "                n_val_drops+=1\n",
    "                # if n_val_drops == MAX_VAL_DROPS:\n",
    "                #     print(\"[early stopping: {} epochs]\".format(it))\n",
    "                    # break\n",
    "            if (it + 1) % 50 == 0 and not self.silent:\n",
    "                time_elapsed = time.time() - t0_epoch\n",
    "                print(f'[Epoch {it+1}/{self.n_epochs} | Training loss: {train_loss_value:.4f} | Val loss: {val_loss_value:.4f} | ET: {time_elapsed:.2f}]')\n",
    "        self.model.load_state_dict(torch.load(tmp_model_fname))\n",
    "        os.remove(tmp_model_fname)\n",
    "        # self.model = self.model.cpu()\n",
    "        return train_losses, val_losses  \n",
    "\n",
    "    def predict_proba(self, X):        \n",
    "        X = torch.from_numpy(X.astype(np.float32))\n",
    "        X_ = X.to(self.device)        \n",
    "        self.model = self.model.to(self.device) \n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_hat_prob = torch.nn.functional.sigmoid(self.model(X_))\n",
    "            y_hat_prob =  y_hat_prob.cpu().numpy()\n",
    "        return y_hat_prob\n",
    "\n",
    "    def predict(self, X):        \n",
    "        y_hat_prob = self.predict_proba(X)\n",
    "        threshold = 0.5 \n",
    "        y_hat = (y_hat_prob > threshold)\n",
    "        return y_hat\n",
    "\n",
    "def get_device(silent=False):\n",
    "    if torch.cuda.is_available():       \n",
    "        device = torch.device(\"cuda\")\n",
    "        if not silent:            \n",
    "            print('GPU device name:', torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        if not silent:\n",
    "            print('No GPU available, using the CPU instead.')        \n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "H5SjTOgye0pB"
   },
   "outputs": [],
   "source": [
    "def train_classifier(X_train, Y_train, X_val, Y_val, \n",
    "                     init_seed, shuffle_seed=None, input_dimension=None):    \n",
    "    if CLASSIFIER == \"torch\":        \n",
    "        x = MyLinearModel(in_dim=input_dimension, out_dim=1, \n",
    "                    loss_fn=torch.nn.BCEWithLogitsLoss(), \n",
    "                    init_seed=init_seed, n_epochs=500, \n",
    "                    default_lr=0.1, batch_size=None, \n",
    "                    shuffle_seed=shuffle_seed, silent=False,\n",
    "                    shuffle=True) \n",
    "        x.fit(X_train, Y_train, X_val, Y_val)\n",
    "    elif CLASSIFIER == \"sklearn\":\n",
    "        x = SGDClassifier(loss=\"log\", random_state=shuffle_seed)\n",
    "        x.fit(X_train, Y_train)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return x\n",
    "\n",
    "def evaluate_classifier(model, X_test, Y_test,\n",
    "                   labels, model_name, random_seed, subgroup, res_path=None):\n",
    "    Y_hat = model.predict(X_test)\n",
    "    Y_hat_prob = model.predict_proba(X_test)\n",
    "    #get probabilities for the positive class\n",
    "    if CLASSIFIER == 'sklearn':\n",
    "        Y_hat_prob = Y_hat_prob[:,labels[1]]    \n",
    "    microF1 = f1_score(Y_test, Y_hat, average=\"micro\") \n",
    "    macroF1 = f1_score(Y_test, Y_hat, average=\"macro\") \n",
    "    try:\n",
    "        aurocc = roc_auc_score(Y_test, Y_hat_prob)\n",
    "    except ValueError:\n",
    "        aurocc = 0\n",
    "    try:\n",
    "        prec, rec, thresholds = precision_recall_curve(Y_test, Y_hat)\n",
    "        auprc = auc(rec, prec)\n",
    "    except ValueError:\n",
    "        auprc = 0\n",
    "    try:\n",
    "        tn, fp, fn, tp = confusion_matrix(Y_test, Y_hat).ravel()\n",
    "        specificity = tn / (tn+fp)\n",
    "        sensitivity = tp / (fn+tp)\n",
    "    except ValueError:\n",
    "        specificity, sensitivity = 0, 0\n",
    "    \n",
    "    res = {\"model\":model_name, \n",
    "            \"seed\":random_seed,  \n",
    "            \"group\":subgroup,    \n",
    "            \"microF1\":round(microF1,3),\n",
    "            \"macroF1\":round(macroF1,3),\n",
    "            \"auroc\":round(aurocc,3),\n",
    "            \"auprc\":round(auprc,3),\n",
    "            \"specificity\":round(specificity,3),\n",
    "            \"sensitivity\":round(sensitivity,3)           \n",
    "            }\n",
    "\n",
    "    if res_path is not None:    \n",
    "        helpers.save_results(res, res_path, sep=\"\\t\")\n",
    "    return res\n",
    "\n",
    "def vectorize_train(df_train, df_val, subject_ids):\n",
    "    #vectorize labels\n",
    "    train_Y = df_train[\"Y\"]\n",
    "    val_Y = df_val[\"Y\"]           \n",
    "    \n",
    "    label_vocab = vectorizer.get_labels_vocab(train_Y+val_Y)\n",
    "    train_Y,_ = vectorizer.label2idx(train_Y, label_vocab)\n",
    "    val_Y,_ = vectorizer.label2idx(val_Y, label_vocab)\n",
    "    \n",
    "    #get the subject id indices\n",
    "    train_idxs = [subject_ids.index(i) for i in list(df_train[\"SUBJECT_ID\"])] \n",
    "    val_idxs = [subject_ids.index(i) for i in list(df_val[\"SUBJECT_ID\"])] \n",
    "\n",
    "    return train_idxs, train_Y, val_idxs, val_Y, label_vocab\n",
    "\n",
    "def vectorize_test(df_test, subject_ids, label_vocab):    \n",
    "    subgroup_idxs = defaultdict(dict)             \n",
    "    #vectorize labels               \n",
    "    test_Y,_ = vectorizer.label2idx(df_test[\"Y\"], label_vocab)   \n",
    "    test_idxs = [subject_ids.index(i) for i in list(df_test[\"SUBJECT_ID\"])] \n",
    "    subgroup_idxs[\"all\"] = [test_idxs, test_Y]\n",
    "    for group in list(GROUPS.keys()):\n",
    "        #and subgroups\n",
    "        for subgroup in GROUPS[group]:                \n",
    "            df_subgroup = df_test[df_test[group] == subgroup]\n",
    "            print(\"[subgroup: {} | size: {}]\".format(subgroup, len(df_subgroup)))\n",
    "            #vectorize labels               \n",
    "            test_Y_G,_ = vectorizer.label2idx(df_subgroup[\"Y\"], label_vocab)            \n",
    "            #get indices into the feature matrix\n",
    "            idxs = [subject_ids.index(i) for i in list(df_subgroup[\"SUBJECT_ID\"])] \n",
    "            if subgroup == \"M\":\n",
    "                subgroup = \"men\"\n",
    "            elif subgroup == \"F\":\n",
    "                subgroup = \"women\"\n",
    "            subgroup_idxs[subgroup.lower()] = [idxs, test_Y_G]\n",
    "\n",
    "    return test_idxs, test_Y, subgroup_idxs\n",
    "\n",
    "def get_features(data, vocab_size, feature_type, word_vectors=None):\n",
    "    if feature_type == \"BOW-BIN\":\n",
    "        X = features.BOW(data, vocab_size,sparse=True)\n",
    "    elif feature_type == \"BOW-FREQ\":\n",
    "        X = features.BOW_freq(data, vocab_size,sparse=True)\n",
    "    elif feature_type == \"BOE-BIN\":\n",
    "        X = features.BOE(data, word_vectors,\"bin\")\n",
    "    elif feature_type == \"BOE-SUM\": \n",
    "        X = features.BOE(data, word_vectors,\"sum\")\n",
    "    elif feature_type == \"BERT-POOL\":\n",
    "        X =  transformer_lms.transformer_encode_batches(data, batchsize=64)        \n",
    "    elif feature_type == \"BERT-CLS\":\n",
    "        X =  transformer_lms.transformer_encode_batches(data, cls_features=True,\n",
    "                                                        batchsize=64)        \n",
    "    elif feature_type == \"MULTI-BERT-POOL\":\n",
    "        X =  transformer_encoders.encode_multi_sequences(data, 10, batchsize=32,\n",
    "                                                         tmp_path=TMP_PATH)\n",
    "    elif feature_type == \"MULTI-BERT-CLS\":\n",
    "        X =  transformer_encoders.encode_multi_sequences(data, 10, \n",
    "                                                         cls_features=True,\n",
    "                                                         batchsize=64,\n",
    "                                                         tmp_path=TMP_PATH)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return X\n",
    "\n",
    "def extract_features(feature_type, path):\n",
    "    X = read_cache(path+\"feats_{}\".format(feature_type))\n",
    "    if X:\n",
    "        print(\"[reading cached features]\")\n",
    "        subject_ids, X_feats = X\n",
    "    else:\n",
    "        print(\"[computing {} features]\".format(feature_type))\n",
    "        df = pd.read_csv(path+\"patients.csv\", sep=\"\\t\", header=0)\n",
    "        subject_ids = list(df[\"SUBJECT_ID\"])\n",
    "        docs = list(df[\"TEXT\"])\n",
    "        if \"BERT\" in feature_type:\n",
    "            X_feats = get_features(docs, None, feature_type)\n",
    "        else:\n",
    "            X, word_vocab = vectorizer.docs2idx(docs)\n",
    "            X_feats = get_features(X,len(word_vocab),feature_type)\n",
    "        #save features\n",
    "        print(\"[saving features]\")\n",
    "        write_cache(path+\"feats_{}\".format(feature_type), \n",
    "                    [subject_ids, X_feats])\n",
    "    return subject_ids, X_feats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6v8lR5X0cp0i"
   },
   "outputs": [],
   "source": [
    "def read_dataset(path, dataset_name, df_patients):    \n",
    "    df_train = pd.read_csv(\"{}/{}_train.csv\".format(path, dataset_name), \n",
    "                           sep=\"\\t\", header=0)\n",
    "    df_test  = pd.read_csv(\"{}/{}_test.csv\".format(path, dataset_name),\n",
    "                           sep=\"\\t\", header=0)\n",
    "    df_val   = pd.read_csv(\"{}/{}_val.csv\".format(path, dataset_name),\n",
    "                           sep=\"\\t\", header=0)\n",
    "    #set indices\n",
    "    df_patients.set_index(\"SUBJECT_ID\", inplace=True)\n",
    "    df_train.set_index(\"SUBJECT_ID\", inplace=True)\n",
    "    df_test.set_index(\"SUBJECT_ID\", inplace=True)\n",
    "    df_val.set_index(\"SUBJECT_ID\", inplace=True)\n",
    "\n",
    "    df_train = df_train.join(df_patients, on=\"SUBJECT_ID\", \n",
    "                             how=\"inner\", lsuffix=\"N_\").reset_index()\n",
    "    df_test = df_test.join(df_patients, on=\"SUBJECT_ID\", \n",
    "                           how=\"inner\", lsuffix=\"N_\").reset_index()\n",
    "    df_val = df_val.join(df_patients, on=\"SUBJECT_ID\", \n",
    "                         how=\"inner\", lsuffix=\"N_\").reset_index()\n",
    "\n",
    "    return df_train, df_test, df_val   \n",
    "\n",
    "def read_cache(path):\n",
    "    X = None\n",
    "    try:\n",
    "        with open(path, \"rb\") as fi:            \n",
    "            X = dill.load(fi)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    return X\n",
    "\n",
    "def write_cache(path, o):\n",
    "    dirname = os.path.dirname(path)\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    with open(path, \"wb\") as fo:\n",
    "        dill.dump(o, fo)\n",
    "\n",
    "def clear_cache(cache_path, model=\"*\", dataset=\"*\", group=\"*\", ctype=\"*\"):\n",
    "    assert ctype in [\"*\",\"res*\",\"feats\"]\n",
    "    file_paths = os.listdir(cache_path)\n",
    "    pattern = \"{}_{}_{}_*_{}.pkl\".format(dataset, model, group, ctype).lower()\n",
    "    for fname in file_paths:\n",
    "        if fnmatch.fnmatch(fname, pattern):\n",
    "            os.remove(cache_path+\"/\"+fname)\n",
    "            print(\"cleared file: {}\".format(fname))      \n",
    "\n",
    "def run(data_path, dataset, features_path, feature_type, cache_path, \n",
    "                  subsample=False):\n",
    "    df_patients = pd.read_csv(features_path+\"patients.csv\", \n",
    "                              sep=\"\\t\", header=0).drop(columns=[\"TEXT\"])\n",
    "    df_train, df_test, df_val = read_dataset(data_path, dataset, df_patients)\n",
    "    print(\"[train/test set size: {}/{}]\".format(len(df_train), len(df_test)))\n",
    "    print(\"[{} classifier]\".format(CLASSIFIER))\n",
    "    subject_ids, feature_matrix = extract_features(feature_type, features_path)\n",
    "    train_idx, train_Y, val_idx, val_Y, label_vocab = vectorize_train(df_train, \n",
    "                                                                       df_val, \n",
    "                                                                       subject_ids)\n",
    "    test_idxs, test_Y, subgroup_idxs = vectorize_test(df_test, subject_ids, label_vocab) \n",
    "    #slice the feature matrix to get the corresponding instances\n",
    "    train_X = feature_matrix[train_idx, :]    \n",
    "    val_X = feature_matrix[val_idx, :]\n",
    "    test_X = feature_matrix[test_idxs,:]\n",
    "    random.seed(1) #ensure repeateable runs \n",
    "    random_seeds = random.sample(range(0, 10000), N_SEEDS)        \n",
    "    incremental_results = defaultdict(list) \n",
    "    test_sets = {}\n",
    "    ##train/test classifier for each random seed pair\n",
    "    for init_seed, shuffle_seed in itertools.product(random_seeds,repeat=2):        \n",
    "        seed = \"{}x{}\".format(init_seed, shuffle_seed)\n",
    "        res_fname = \"{}_{}_res{}.pkl\".format(dataset, feature_type, seed).lower()                \n",
    "        #look for cached results\n",
    "        curr_results = None\n",
    "        if cache_path: curr_results = read_cache(cache_path+res_fname)              \n",
    "        if not curr_results:\n",
    "            curr_results = {}\n",
    "            print(\" > seed: {}\".format(seed))                        \n",
    "            model = train_classifier(train_X, train_Y,val_X, val_Y,  \n",
    "                                     input_dimension=train_X.shape[1],\n",
    "                                     init_seed=init_seed, \n",
    "                                     shuffle_seed=shuffle_seed)                                                      \n",
    "            #test each subgroup (note thtat *all* is also a subgroup)\n",
    "            for subgroup in subgroup_idxs.keys():                                \n",
    "                test_idx_G, test_Y_G = subgroup_idxs[subgroup]                 \n",
    "                test_X_G = feature_matrix[test_idx_G, :]                \n",
    "                res_g = evaluate_classifier(model, test_X_G, test_Y_G, \n",
    "                                            label_vocab, feature_type, seed, subgroup)                \n",
    "                curr_results[subgroup]= res_g               \n",
    "            #cache results\n",
    "            if cache_path: write_cache(cache_path+res_fname, curr_results)                \n",
    "        else:\n",
    "            print(\"loaded cached results | seed: {}\".format(seed))        \n",
    "        \n",
    "        incremental_results = merge_results(curr_results, incremental_results, \n",
    "                                            list(subgroup_idxs.keys()))\n",
    "    #build dataframes \n",
    "    df_results = results_to_df(incremental_results, subgroup_idxs.keys())\n",
    "    return df_results\n",
    "\n",
    "def merge_results(curr_results, results, subgroups):\n",
    "    #append results    \n",
    "    for subgroup in subgroups:                \n",
    "        res = curr_results[subgroup]\n",
    "        results[subgroup].append(res)            \n",
    "    return results\n",
    "\n",
    "def results_to_df(results, subgroups):\n",
    "    df_results = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))    \n",
    "    df_res = pd.DataFrame(results[\"all\"])            \n",
    "    for subgroup in subgroups:        \n",
    "        # if subgroup == \"all\": continue\n",
    "        df_res_g = pd.DataFrame(results[subgroup])        \n",
    "        df_res_delta = df_res_g.sub(df_res.iloc[:,3:])\n",
    "        # from pdb import set_trace; set_trace()\n",
    "        df_res_delta[\"model\"] = df_res_g[\"model\"]\n",
    "        df_res_delta[\"seed\"] = df_res_g[\"seed\"]\n",
    "        df_res_delta[\"group\"] = df_res_g[\"group\"]   \n",
    "        df_results[subgroup][\"results\"] = df_res_g\n",
    "        df_results[subgroup][\"delta\"] = df_res_delta\n",
    "        \n",
    "    return dict(df_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTyzgoy4vx64"
   },
   "source": [
    "# Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LVpc3ZQ-jsaV"
   },
   "outputs": [],
   "source": [
    "def run_analyses(data_path, dataset, features_path, feature_type, results_path, \n",
    "                 cache_path, clear_results=False, tune_metric=None, plot_metric=\"auroc\"):    \n",
    "\n",
    "    if clear_results:\n",
    "        clear_cache(cache_path, model=feature_type, dataset=dataset, ctype=\"res*\")\n",
    "    if tune_metric:\n",
    "        df_results = tune_run(data_path, dataset, features_path, feature_type, cache_path, tune_metric)  \n",
    "        fname = \"{}_{}_all_tuned_res.pkl\".format(dataset, feature_type).lower()\n",
    "    else:\n",
    "        df_results = run(data_path, dataset, features_path, feature_type, cache_path)         \n",
    "        fname = \"{}_{}_all_res.pkl\".format(dataset, feature_type).lower()\n",
    "        \n",
    "    #save results\n",
    "    if not os.path.exists(results_path): os.makedirs(results_path)  \n",
    "    write_cache(results_path+fname, df_results)\n",
    "    if plot_metric:           \n",
    "        plot_scatters(df_results, plot_metric, dataset)\n",
    "        plot_deltas(df_results, plot_metric, dataset)\n",
    "    return df_results               \n",
    "\n",
    "#Run All the tasks\n",
    "def run_tasks(data_path, tasks_fname, features_path, feature_type, results_path, cache_path,  \n",
    "             reset=False, tune_metric=None, plot_metric=None, mini_tasks=True):\n",
    "    #if reset delete the completed tasks file\n",
    "    if reset: reset_tasks(cache_path)    \n",
    "    with open(data_path+tasks_fname,\"r\") as fid:\n",
    "        for i,l in enumerate(fid):\n",
    "            if i > N_TASKS: break\n",
    "            fname, task_name = l.strip(\"\\n\").split(\",\")            \n",
    "            dataset = \"mini-\"+fname if mini_tasks else fname\n",
    "            # dataset = fname\n",
    "            if is_task_done(cache_path, dataset): \n",
    "                print(\"[dataset: {} already processed]\".format(dataset))\n",
    "                continue                        \n",
    "            print(\"******** {} {} ********\".format(task_name, dataset))      \n",
    "            run_analyses(data_path, dataset, features_path, feature_type, results_path, \n",
    "                         cache_path, clear_results=False, tune_metric=tune_metric, \n",
    "                         plot_metric=plot_metric)\n",
    "            task_done(cache_path, dataset)\n",
    "\n",
    "def task_done(path,  task):\n",
    "    dirname = os.path.dirname(path)\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    with open(path+\"completed_tasks.txt\", \"a\") as fod:\n",
    "        fod.write(task+\"\\n\")\n",
    "\n",
    "def reset_tasks(path):\n",
    "    dirname = os.path.dirname(path)\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    with open(path+\"completed_tasks.txt\", \"w\") as fod:\n",
    "        fod.write(\"\")\n",
    "\n",
    "def is_task_done(path,  task):\n",
    "    try:\n",
    "        with open(path+\"completed_tasks.txt\", \"r\") as fid:\n",
    "            tasks = fid.read().split(\"\\n\")            \n",
    "        return task in set(tasks)\n",
    "    except FileNotFoundError:\n",
    "        #create file if not found\n",
    "        dirname = os.path.dirname(path)\n",
    "        if not os.path.exists(dirname):\n",
    "            os.makedirs(dirname)\n",
    "        with open(path+\"completed_tasks.txt\", \"w\") as fid:\n",
    "            fid.write(\"\")\n",
    "        return False\n",
    "\n",
    "def plot_densities(df, ax, title):\n",
    "    ax.set_title(title)\n",
    "    for y in PLOT_VARS:        \n",
    "        try:\n",
    "            df.plot.kde(ax=ax, x=\"seed\", y=y)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "def plot_scatters(results, metric, title):\n",
    "    n_rows=2\n",
    "    n_cols = 3    \n",
    "    fig, ax = plt.subplots(n_rows, n_cols,  figsize=(12,5), sharex=True, sharey=True)\n",
    "    #current coloramap\n",
    "    cmap = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    coords = list(itertools.product(range(n_rows),range(n_cols)))   \n",
    "    try:\n",
    "        del results[\"all\"]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    for subgroup, col, coord in zip(results.keys(), cmap, coords ):\n",
    "        df = results[subgroup][\"results\"]\n",
    "        df_delta = results[subgroup][\"delta\"]\n",
    "        \n",
    "        df_all = df.merge(df_delta, on=[\"model\",\"seed\",\"group\"],\n",
    "                                      suffixes=[None, \"_delta\"])\n",
    "        # print(len(df_all))\n",
    "        jitter_x = np.random.randn(len(df_all)) * .005\n",
    "        jitter_y = np.random.randn(len(df_all)) * .005\n",
    "        #get absolute values for the deltas    \n",
    "        df_all[metric+\"_delta\"] = df_all[metric+\"_delta\"].abs() + jitter_y\n",
    "        df_all[metric] += jitter_x\n",
    "\n",
    "        df_all.plot.scatter(x=metric,y=metric+\"_delta\",\n",
    "                            c=col, ax=ax[coord[0]][coord[1]])\n",
    "        ax[coord[0]][coord[1]].set_title(subgroup)\n",
    "    fig.suptitle(title, y=1.02)\n",
    "    plt.tight_layout()    \n",
    "    \n",
    "def plot_deltas(results, metric, title):\n",
    "    try:\n",
    "        del results[\"all\"]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    df_delta = pd.concat([results[g][\"delta\"] for g in list(results.keys())])    \n",
    "    #transform results into \"long format\"\n",
    "    df_delta_long = df_delta.melt(id_vars=[\"seed\",\"model\",\"group\"], \n",
    "                                  value_vars=[metric], \n",
    "                                  var_name=\"metric\", value_name=\"delta\")\n",
    "    jitter_x = np.random.randn(len(df_delta_long)) * .005\n",
    "    df_delta_long[\"delta\"]+=jitter_x\n",
    "    g = sns.catplot(x=\"group\", y=\"delta\", data=df_delta_long, \n",
    "                    col=\"metric\",sharey=True,legend=False)    \n",
    "    lim = max(df_delta_long[\"delta\"].abs()) + 0.05\n",
    "    \n",
    "    for ax in g.axes[0]:\n",
    "        ax.axhline(0, ls='--',c=\"r\")\n",
    "        ax.set_ylim([-lim,lim])\n",
    "    plt.suptitle(title, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()  \n",
    "\n",
    "def plot_analyses(results_path, dataset, feature_type, plot_metric, tune_metric=None):\n",
    "    if tune_metric:\n",
    "        fname = \"{}_{}_all_tuned_res.pkl\".format(dataset, feature_type).lower()\n",
    "    else:        \n",
    "        fname = \"{}_{}_all_res.pkl\".format(dataset, feature_type).lower()\n",
    "\n",
    "    df_results = read_cache(results_path+fname)    \n",
    "    if df_results:\n",
    "        plot_scatters(df_results, plot_metric, dataset)\n",
    "        plot_deltas(df_results, plot_metric, dataset)\n",
    "\n",
    "\n",
    "def plot_tasks(data_path, tasks_fname, feature_type, results_path, \n",
    "               mini_tasks=True, plot_metric=None, tune_metric=None):\n",
    "    with open(data_path+tasks_fname,\"r\") as fid:        \n",
    "        for i,l in enumerate(fid):            \n",
    "            fname, task_name = l.strip(\"\\n\").split(\",\")\n",
    "            dataset = \"mini-\"+fname if mini_tasks else fname\n",
    "            plot_analyses(results_path, dataset, feature_type, plot_metric, tune_metric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4o3v3P3njsaj"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QmBAlSIDFeOp",
    "outputId": "6466b146-c430-42b1-9e82-0c15cd0c59d0",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset=\"IHM\"\n",
    "dataset=\"mini-\"+dataset\n",
    "CLASSIFIER=\"sklearn\"\n",
    "PLOT_METRIC=\"auroc\"\n",
    "run_analyses(INPUT_PATH, dataset, FEATURES_PATH, MODEL, OUTPUT_PATH, TMP_PATH, \n",
    "             clear_results=False, tune_metric=None, plot_metric=PLOT_METRIC)\n",
    "plot_analyses(OUTPUT_PATH, dataset, MODEL, plot_metric=PLOT_METRIC, tune_metric=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxyq5bgZ3qMm"
   },
   "outputs": [],
   "source": [
    "CLASSIFIER=\"sklearn\"\n",
    "# run_analyses(INPUT_PATH, dataset, FEATURES_PATH, MODEL, OUTPUT_PATH, None, clear_results=False, tune_metric=None, subsample=False, plots=True)\n",
    "plot_analyses(OUTPUT_PATH, dataset, MODEL, dataset, tune_metric=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fXq6jZL6pnQ_",
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Run tasks\n",
    "# run_tasks(INPUT_PATH, \"tasks.txt\", FEATURES_PATH, MODEL, OUTPUT_PATH, TMP_PATH, reset=True, \n",
    "#           tune_metric=None, plot_metric=None, mini_tasks=True)\n",
    "plot_tasks(INPUT_PATH, \"tasks.txt\", MODEL, OUTPUT_PATH, mini_tasks=True, plot_metric=PLOT_METRIC, tune_metric=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ySito54jsbH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Run tasks with tuning\n",
    "TUNE_METRIC = \"auprc\"\n",
    "run_tasks(INPUT_PATH, \"tasks.txt\", FEATURES_PATH, MODEL, TUNE_TMP_PATH, TUNE_OUTPUT_PATH, mini_tasks=True, reset=True, tune_metric=TUNE_METRIC)\n",
    "# plot_tasks(INPUT_PATH, \"tasks.txt\", MODEL, TUNE_OUTPUT_PATH, mini_tasks=True, tune_metric=TUNE_METRIC)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "nIwSdPdMjsbJ"
   ],
   "name": "MIMIC_Outcomes_Torch",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}